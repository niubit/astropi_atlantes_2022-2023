{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f52e32",
   "metadata": {},
   "source": [
    "# Overlay fotos\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Ahora que tenemos controladas las cuestiones de conversión entre posiciones de píxeles en las fotos y coordenadas terrestres, vamos a enfocarnos a utilizar las librerías que nos permitirán manipular de forma automatizada las fotos y no con editores como Gimp que es lo que hemos utilizado hasta ahora para generar algunas de las representaciones mostradas en los anteriores cuadernos.\n",
    "\n",
    "Vamos a utilizar la potente librería [OpenCV](https://docs.opencv.org/4.x/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b75dfb",
   "metadata": {},
   "source": [
    "## Sede Atlantes\n",
    "\n",
    "Vamos a empezar haciendo un sencillo ejercicio. Estimamos que la ciudad de Zaragoza, sede del equipo Atlantes, aparece entre las fotos 494 y 496 aunque, como la zona está cubierta por las nubes, no podemos señalar visualmente la posición con precisión, pero sí matemáticamente utilizando nuestras nuevas habilidades de cálculo.\n",
    "\n",
    "Lo que queremos lograr es una pequeña animación con los 3 fotogramas en los que aparezca señalada la ciudad de Zaragoza en su posición correcta en cada uno de los fotogramas. Partimos de las fotos ya rotadas (que almacenamos en el directorio `atlantes_2021-2022_rotadas` al final del primer cuaderno) y de la estructura de datos JSON donde almacenamos los ángulos α de todas ellas (también almacenado en el fichero `alphas_445-622.json` al final del primer cuaderno). La secuencia de trabajo será más o menos la siguiente:\n",
    "\n",
    "1. Para cada fotograma:\n",
    "    1. Cargar con OpenCV el fotograma.\n",
    "    2. Convertir las coordenadas de la ciudad de Zaragoza a posición de pixel del fotograma.\n",
    "    3. Colocar una marca centrada en el pixel calculado en el paso anterior.\n",
    "    4. Añadir el fotograma resultante a la animación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab3590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pandas\n",
    "from geopy import distance, point\n",
    "\n",
    "# Constantes\n",
    "FOTO_W = 3280\n",
    "FOTO_H = 2464\n",
    "S_W = 6.287\n",
    "F = 5\n",
    "PHOTO_ROT_DIR_PATH = \"atlantes_2021-2022_rotadas\"\n",
    "ATLANTES_FILE = \"atlantes_2021-2022.csv\"\n",
    "ALPHAS_FILE = \"alphas_445-622.json\"\n",
    "LOGO_FILE = \"2018_logo-circulo_100px.png\"\n",
    "ANIM_FILE = \"anim.avi\"\n",
    "PHOTO_START = 494\n",
    "PHOTO_END = 496\n",
    "RESULT_WIDTH = 640\n",
    "RESULT_HEIGHT = 480\n",
    "FPS = 3\n",
    "OUTPUT = True    # True: Salida a fichero; False: Salida a pantalla\n",
    "\n",
    "pnt_X = point.Point(41.6516859, -0.9300003) # Zaragoza\n",
    "\n",
    "\n",
    "# Calcula el pixel (X,Y) correspondiente a unas coordenadas (latitud,longitud) de una foto cuyo pixel central tiene\n",
    "# unas coordenadas conocidas.\n",
    "# Argumentos:\n",
    "#     * pnt_I: Punto (clase geopy.point.Point) medido por AstroPi durante la captura de la foto como posición\n",
    "#              de la ISS.\n",
    "#     * alt:   Altitud de la ISS durante la captura de la foto.\n",
    "#     * alpha: Ángulo de la órbita respecto del ecuador durante la captura de la foto.\n",
    "#     * pnt_X: Punto (clase geopy.point.Point) del que queremos obtener su posición en la foto.\n",
    "# Resutado:\n",
    "#     Tupla (X,Y) con la posición del pixel correspondiente a las coordenadas del punto pnt_X.\n",
    "def coords2pixel(pnt_I, alpha, alt, pnt_X):\n",
    "    pnt_O = distance.great_circle(meters=52329).destination(pnt_I, bearing=-61.69-alpha)\n",
    "    pnt_O.altitude = alt\n",
    "    \n",
    "    d_w = S_W * pnt_O.altitude / F\n",
    "    d_h = d_w * FOTO_H / FOTO_W\n",
    "    pnt_T = distance.great_circle(meters=d_h/2).destination(pnt_O, bearing=0)\n",
    "    pnt_B = distance.great_circle(meters=d_h/2).destination(pnt_O, bearing=180)\n",
    "    pnt_L = distance.great_circle(meters=d_w/2).destination(pnt_O, bearing=270)\n",
    "    pnt_R = distance.great_circle(meters=d_w/2).destination(pnt_O, bearing=90)\n",
    "    t_lat, t_lon = pnt_T.latitude, pnt_T.longitude\n",
    "    b_lat, b_lon = pnt_B.latitude, pnt_B.longitude\n",
    "    l_lat, l_lon = pnt_L.latitude, pnt_L.longitude\n",
    "    r_lat, r_lon = pnt_R.latitude, pnt_R.longitude\n",
    "    x_lat, x_lon = pnt_X.latitude, pnt_X.longitude\n",
    "    \n",
    "    # Normalizamos las longitudes para que se puedan hacer los cálculos proporcionales\n",
    "    if l_lon * r_lon < 0:\n",
    "        if l_lon < -90:\n",
    "            l_lon += 360\n",
    "        if r_lon < -90:\n",
    "            r_lon += 360\n",
    "        if x_lon < -90:\n",
    "            x_lon += 360\n",
    "    \n",
    "    if not (b_lat <= x_lat <= t_lat) or not (l_lon <= x_lon <= r_lon):\n",
    "        raise Exception(f\"Las coordenadas ({pnt_X.latitude},{x_lon}) quedan fuera de la foto.\")\n",
    "\n",
    "    X = FOTO_W * ( 1 - (r_lon - x_lon) / (r_lon - l_lon))\n",
    "    Y = FOTO_H * (t_lat - x_lat) / (t_lat - b_lat)\n",
    "    return (round(X), round(Y))\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/70578600/how-to-merge-one-rgba-and-one-rgb-images-in-opencv\n",
    "def alphaMerge(small_foreground, background, x, y):\n",
    "    \"\"\"\n",
    "    Puts a small BGRA picture in front of a larger BGR background.\n",
    "    :param small_foreground: The overlay image. Must have 4 channels.\n",
    "    :param background: The background. Must have 3 channels.\n",
    "    :param x: X position where to put the overlay's center.\n",
    "    :param y: Y position where to put the overlay's center.\n",
    "    :return: a copy of the background with the overlay added.\n",
    "    \"\"\"\n",
    "    result = background.copy()\n",
    "    # From everything I read so far, it seems we need the alpha channel separately\n",
    "    # so let's split the overlay image into its individual channels\n",
    "    fg_b, fg_g, fg_r, fg_a = cv2.split(small_foreground)\n",
    "    # Make the range 0...1 instead of 0...255\n",
    "    fg_a = fg_a / 255.0\n",
    "    # Multiply the RGB channels with the alpha channel\n",
    "    label_rgb = cv2.merge([fg_b * fg_a, fg_g * fg_a, fg_r * fg_a])\n",
    "    # Work on a part of the background only\n",
    "    height, width = small_foreground.shape[0], small_foreground.shape[1]\n",
    "    mid_h = int(height/2)\n",
    "    mid_w = int(width/2)\n",
    "    part_of_bg = result[y-mid_h:y+mid_h, x-mid_w:x+mid_w, :]\n",
    "    # Same procedure as before: split the individual channels\n",
    "    bg_b, bg_g, bg_r = cv2.split(part_of_bg)\n",
    "    # Merge them back with opposite of the alpha channel\n",
    "    part_of_bg = cv2.merge([bg_b * (1 - fg_a), bg_g * (1 - fg_a), bg_r * (1 - fg_a)])\n",
    "    # Add the label and the part of the background\n",
    "    cv2.add(label_rgb, part_of_bg, part_of_bg)\n",
    "    # Replace a part of the background\n",
    "    result[y-mid_h:y+mid_h, x-mid_w:x+mid_w, :] = part_of_bg\n",
    "    return result\n",
    "\n",
    "\n",
    "path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "photo_rot_dir_path = os.path.join(path, PHOTO_ROT_DIR_PATH)\n",
    "atlantes_file_path = os.path.join(path, ATLANTES_FILE)\n",
    "alphas_file_path = os.path.join(path, ALPHAS_FILE)\n",
    "logo_file_path = os.path.join(path, LOGO_FILE)\n",
    "\n",
    "alphas_file = open(alphas_file_path)\n",
    "alphas_json = json.load(alphas_file)\n",
    "\n",
    "atlantes_data = pandas.read_csv(atlantes_file_path)\n",
    "\n",
    "logo_cv = cv2.imread(logo_file_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "if OUTPUT:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
    "    anim_file_path = os.path.join(path, ANIM_FILE)\n",
    "    video = cv2.VideoWriter(anim_file_path, fourcc, float(FPS), (RESULT_WIDTH, RESULT_HEIGHT))\n",
    "\n",
    "for i in range(PHOTO_START, PHOTO_END+1):\n",
    "    pnt_I = point.Point(atlantes_data.latitude[i-1], atlantes_data.longitude[i-1])\n",
    "    alpha = alphas_json[str(i)]\n",
    "    altitude = atlantes_data.elevation[i-1]\n",
    "    photo_path = os.path.join(photo_rot_dir_path, \"atlantes_%d.jpg\" % (i))\n",
    "    photo_cv = cv2.imread(photo_path)\n",
    "    try:\n",
    "        (X, Y) = coords2pixel(pnt_I, alpha, altitude, pnt_X)\n",
    "        photo_cv = alphaMerge(logo_cv, photo_cv, X, Y)\n",
    "    except:\n",
    "        pass\n",
    "    photo_cv = cv2.resize(photo_cv, (RESULT_WIDTH, RESULT_HEIGHT))\n",
    "    if OUTPUT:\n",
    "        video.write(photo_cv)\n",
    "    else:\n",
    "        cv2.imshow(\"Home of Atlantes\", photo_cv)\n",
    "        cv2.waitKey(int(1000/FPS))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "alphas_file.close()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
